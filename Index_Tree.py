from Filters import *
from Similarity_Functions import *
from Similarity_Function_Length_Interval import *

#Index Tree, can generate the adaptive, condensed and prefix index tree, according to the parameters passed
class IndexTree:
    #Tree initializer
    #node records the next nodes or entities in the tree
    #height infers which attribute and filter will be employed at each node
    #the limit is the maximum height of conditions in the tree, which nodes stores the entities
    #filters is the list of filters that will be used
    #attributes is the list of attributes that will be used
    def __init__(self,height, key, limit, filters, attributes):
        self.node = []
        self.height = height
        self.key = key
        self.limit = limit
        self.filters = filters
        self.attributes = attributes
    
    #Function to individually insert a entity of the dataset
    def Insert_Dataset(self,dataset):
        #this variable guarantee access to our filters and functions without declaring them
        filter_and_function_list = globals()
        for entity in dataset:
            inserted = False
            #if the height is equal to the limit then we insert the entity instead of creating a intermediate node
            if(self.height == self.limit):
                self.node.append(entity)
                inserted = True
            
            else:
                #computates the condition generated by the filter in the correspondent attribute of the entities
                condition = filter_and_function_list[self.filters[self.height]](entity[self.attributes[self.height]])
                for b in range(len(self.node)):
                    #the positional filter has two conditions, one employed in the construction and other in the validation of the foreign dataset
                    if("Positional" in self.filters[self.height]):
                        if(self.node[b].key[0] == condition[0]):
                            self.node[b].Insert_Dataset([entity])
                            inserted = True
                            break
                    #all filters with only one output uses this section
                    else:
                        if(self.node[b].key == condition):
                            self.node[b].Insert_Dataset([entity])
                            inserted = True
                            break
                #if the entity was not inserted, then we create a node that satisfies its conditions and then insert it        
                if not inserted:
                    self.node.append(IndexTree(self.height+1, condition, self.limit, self.filters, self.attributes))
                    self.node[-1].Insert_Dataset([entity])
                    inserted = True
            
    #The similarity function is executed in this strech
    #to perform the join we need the foreign dataset, which will be joined to the input dataset
    #its is necessary to specify the similarity function which will be employed and the respective threshold
    def Similarity_Join(self, foreign_dataset, threshold, similarity_function):
        #this variable guarantee access to our filters and functions without declaring them
        filter_and_function_list = globals()
        
        #output
        identified_similar_pairs = []
        
        #iterating over the foreign dataset
        for a in range(len(foreign_dataset)):
            for b in range(len(self.node)):
                #if the height is equal to the limit, we compute the similarity between the entity and all entities in the node
                if(self.height == self.limit):
                    similarity = filter_and_function_list[similarity_function](self.node[b], foreign_dataset[a], threshold)
                    #all functions return a tuple of values which are (entity A, entitiy B, similarity between A and B)
                    if(similarity[2]>=threshold):
                        identified_similar_pairs.append(similarity)
                else:
                    #in this strech we will display each available filter validation
                    if("Positional" in self.filters[self.height]):
                        #this bound is the second condition of the positional filter
                        bound = len(foreign_dataset[a][self.attributes[self.height]])*threshold
                        key = filter_and_function_list[self.filters[self.height]](foreign_dataset[a][self.attributes[self.height]])
                        #interate over the prefix generated in the positional filter
                        for c in range(len(self.node[b].key[1])):
                            if(self.node[b].key[1][c] in key[1]):
                                index = min(key[1].index(self.node[b].key[1][c]),c)
                                content = c+min(self.node[b].key[2],(key[2]-(index+1)))
                                if(content>=bound):
                                    temp = []
                                    #performing the similarity join at the next node of the tree
                                    temp = self.node[b].Similarity_Join([foreign_dataset[a]],threshold, similarity_function)
                                    for d in range(len(temp)):
                                        identified_similar_pairs.append(temp[d])
                                break
                    #prefix and suffix works similar, with the only difference being the tokens returned by each filter
                    #also, the minhash must share at least one common hash to validate the condition, so all other available filters employ this strech
                    else:
                        key = filter_and_function_list[self.filters[self.height]](foreign_dataset[a][self.attributes[self.height]])
                        temp = []
                        for c in range(len(self.node[b].key)):
                            if(self.node[b].key[c] in key):
                                #performing the similarity join at the next node of the tree
                                temp = self.node[b].Similarity_Join([foreign_dataset[a]], threshold, similarity_function)
                                for d in range(len(temp)):
                                    identified_similar_pairs.append(temp[d])
                                break
                    
        return identified_similar_pairs